{
  "best_metric": 0.7639695019760437,
  "best_model_checkpoint": "/content/drive/My Drive/model_segformer_essai/checkpoint-1860",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 1860,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.026881720430107527,
      "grad_norm": 7.670095920562744,
      "learning_rate": 9e-07,
      "loss": 2.005,
      "step": 10
    },
    {
      "epoch": 0.053763440860215055,
      "grad_norm": 10.088462829589844,
      "learning_rate": 1.9e-06,
      "loss": 1.9725,
      "step": 20
    },
    {
      "epoch": 0.08064516129032258,
      "grad_norm": 6.492823123931885,
      "learning_rate": 2.9e-06,
      "loss": 1.9451,
      "step": 30
    },
    {
      "epoch": 0.10752688172043011,
      "grad_norm": 6.946835517883301,
      "learning_rate": 3.9e-06,
      "loss": 1.8647,
      "step": 40
    },
    {
      "epoch": 0.13440860215053763,
      "grad_norm": 10.74355411529541,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 1.8336,
      "step": 50
    },
    {
      "epoch": 0.16129032258064516,
      "grad_norm": 6.221539497375488,
      "learning_rate": 5.9e-06,
      "loss": 1.7153,
      "step": 60
    },
    {
      "epoch": 0.1881720430107527,
      "grad_norm": 4.8163557052612305,
      "learning_rate": 6.900000000000001e-06,
      "loss": 1.5879,
      "step": 70
    },
    {
      "epoch": 0.21505376344086022,
      "grad_norm": 6.477248668670654,
      "learning_rate": 7.9e-06,
      "loss": 1.4858,
      "step": 80
    },
    {
      "epoch": 0.24193548387096775,
      "grad_norm": 6.342894554138184,
      "learning_rate": 8.9e-06,
      "loss": 1.4031,
      "step": 90
    },
    {
      "epoch": 0.26881720430107525,
      "grad_norm": 7.3747029304504395,
      "learning_rate": 9.900000000000002e-06,
      "loss": 1.2868,
      "step": 100
    },
    {
      "epoch": 0.2956989247311828,
      "grad_norm": 5.035168170928955,
      "learning_rate": 1.09e-05,
      "loss": 1.1668,
      "step": 110
    },
    {
      "epoch": 0.3225806451612903,
      "grad_norm": 5.1812262535095215,
      "learning_rate": 1.18e-05,
      "loss": 1.1485,
      "step": 120
    },
    {
      "epoch": 0.34946236559139787,
      "grad_norm": 5.045464515686035,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 1.0696,
      "step": 130
    },
    {
      "epoch": 0.3763440860215054,
      "grad_norm": 6.39601469039917,
      "learning_rate": 1.3800000000000002e-05,
      "loss": 0.9842,
      "step": 140
    },
    {
      "epoch": 0.4032258064516129,
      "grad_norm": 3.6635937690734863,
      "learning_rate": 1.48e-05,
      "loss": 0.9202,
      "step": 150
    },
    {
      "epoch": 0.43010752688172044,
      "grad_norm": 4.892004489898682,
      "learning_rate": 1.58e-05,
      "loss": 0.9171,
      "step": 160
    },
    {
      "epoch": 0.45698924731182794,
      "grad_norm": 9.1666898727417,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.8457,
      "step": 170
    },
    {
      "epoch": 0.4838709677419355,
      "grad_norm": 6.0901570320129395,
      "learning_rate": 1.78e-05,
      "loss": 0.7652,
      "step": 180
    },
    {
      "epoch": 0.510752688172043,
      "grad_norm": 3.1682467460632324,
      "learning_rate": 1.88e-05,
      "loss": 0.7063,
      "step": 190
    },
    {
      "epoch": 0.5376344086021505,
      "grad_norm": 5.419931888580322,
      "learning_rate": 1.9800000000000004e-05,
      "loss": 0.7173,
      "step": 200
    },
    {
      "epoch": 0.5645161290322581,
      "grad_norm": 1.8655930757522583,
      "learning_rate": 2.08e-05,
      "loss": 0.6715,
      "step": 210
    },
    {
      "epoch": 0.5913978494623656,
      "grad_norm": 2.7235260009765625,
      "learning_rate": 2.18e-05,
      "loss": 0.6441,
      "step": 220
    },
    {
      "epoch": 0.6182795698924731,
      "grad_norm": 2.4127159118652344,
      "learning_rate": 2.2800000000000002e-05,
      "loss": 0.6248,
      "step": 230
    },
    {
      "epoch": 0.6451612903225806,
      "grad_norm": 1.9773547649383545,
      "learning_rate": 2.38e-05,
      "loss": 0.5826,
      "step": 240
    },
    {
      "epoch": 0.6720430107526881,
      "grad_norm": 4.099496364593506,
      "learning_rate": 2.48e-05,
      "loss": 0.5998,
      "step": 250
    },
    {
      "epoch": 0.6989247311827957,
      "grad_norm": 4.007836818695068,
      "learning_rate": 2.58e-05,
      "loss": 0.5761,
      "step": 260
    },
    {
      "epoch": 0.7258064516129032,
      "grad_norm": 2.947108268737793,
      "learning_rate": 2.6800000000000004e-05,
      "loss": 0.5863,
      "step": 270
    },
    {
      "epoch": 0.7526881720430108,
      "grad_norm": 3.906543493270874,
      "learning_rate": 2.7800000000000005e-05,
      "loss": 0.5319,
      "step": 280
    },
    {
      "epoch": 0.7795698924731183,
      "grad_norm": 2.7793047428131104,
      "learning_rate": 2.88e-05,
      "loss": 0.4979,
      "step": 290
    },
    {
      "epoch": 0.8064516129032258,
      "grad_norm": 3.5397567749023438,
      "learning_rate": 2.98e-05,
      "loss": 0.4541,
      "step": 300
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 2.810849666595459,
      "learning_rate": 3.08e-05,
      "loss": 0.4987,
      "step": 310
    },
    {
      "epoch": 0.8602150537634409,
      "grad_norm": 3.371715545654297,
      "learning_rate": 3.18e-05,
      "loss": 0.4424,
      "step": 320
    },
    {
      "epoch": 0.8870967741935484,
      "grad_norm": 3.6917755603790283,
      "learning_rate": 3.2800000000000004e-05,
      "loss": 0.4499,
      "step": 330
    },
    {
      "epoch": 0.9139784946236559,
      "grad_norm": 3.594680070877075,
      "learning_rate": 3.38e-05,
      "loss": 0.4904,
      "step": 340
    },
    {
      "epoch": 0.9408602150537635,
      "grad_norm": 2.2566113471984863,
      "learning_rate": 3.48e-05,
      "loss": 0.3969,
      "step": 350
    },
    {
      "epoch": 0.967741935483871,
      "grad_norm": 5.887082099914551,
      "learning_rate": 3.58e-05,
      "loss": 0.4265,
      "step": 360
    },
    {
      "epoch": 0.9946236559139785,
      "grad_norm": 2.2310380935668945,
      "learning_rate": 3.68e-05,
      "loss": 0.3837,
      "step": 370
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.41451263427734375,
      "eval_mean_iou": 0.6449588772935659,
      "eval_runtime": 2268.9738,
      "eval_samples_per_second": 0.22,
      "eval_steps_per_second": 0.028,
      "step": 372
    },
    {
      "epoch": 1.021505376344086,
      "grad_norm": 4.975039005279541,
      "learning_rate": 3.7800000000000004e-05,
      "loss": 0.3994,
      "step": 380
    },
    {
      "epoch": 1.0483870967741935,
      "grad_norm": 1.3703728914260864,
      "learning_rate": 3.88e-05,
      "loss": 0.3901,
      "step": 390
    },
    {
      "epoch": 1.075268817204301,
      "grad_norm": 6.034954071044922,
      "learning_rate": 3.9800000000000005e-05,
      "loss": 0.4152,
      "step": 400
    },
    {
      "epoch": 1.1021505376344085,
      "grad_norm": 2.039231538772583,
      "learning_rate": 4.08e-05,
      "loss": 0.3693,
      "step": 410
    },
    {
      "epoch": 1.129032258064516,
      "grad_norm": 2.251774787902832,
      "learning_rate": 4.18e-05,
      "loss": 0.3952,
      "step": 420
    },
    {
      "epoch": 1.1559139784946237,
      "grad_norm": 2.6213972568511963,
      "learning_rate": 4.2800000000000004e-05,
      "loss": 0.3566,
      "step": 430
    },
    {
      "epoch": 1.1827956989247312,
      "grad_norm": 1.6302778720855713,
      "learning_rate": 4.38e-05,
      "loss": 0.398,
      "step": 440
    },
    {
      "epoch": 1.2096774193548387,
      "grad_norm": 1.8356823921203613,
      "learning_rate": 4.4800000000000005e-05,
      "loss": 0.301,
      "step": 450
    },
    {
      "epoch": 1.2365591397849462,
      "grad_norm": 2.014042377471924,
      "learning_rate": 4.58e-05,
      "loss": 0.3539,
      "step": 460
    },
    {
      "epoch": 1.2634408602150538,
      "grad_norm": 1.8388441801071167,
      "learning_rate": 4.6800000000000006e-05,
      "loss": 0.3414,
      "step": 470
    },
    {
      "epoch": 1.2903225806451613,
      "grad_norm": 0.8623772859573364,
      "learning_rate": 4.78e-05,
      "loss": 0.3418,
      "step": 480
    },
    {
      "epoch": 1.3172043010752688,
      "grad_norm": 2.29697847366333,
      "learning_rate": 4.88e-05,
      "loss": 0.3464,
      "step": 490
    },
    {
      "epoch": 1.3440860215053765,
      "grad_norm": 3.264181137084961,
      "learning_rate": 4.9800000000000004e-05,
      "loss": 0.3002,
      "step": 500
    },
    {
      "epoch": 1.370967741935484,
      "grad_norm": 1.2443777322769165,
      "learning_rate": 4.970588235294118e-05,
      "loss": 0.2922,
      "step": 510
    },
    {
      "epoch": 1.3978494623655915,
      "grad_norm": 0.792968213558197,
      "learning_rate": 4.933823529411765e-05,
      "loss": 0.2741,
      "step": 520
    },
    {
      "epoch": 1.424731182795699,
      "grad_norm": 2.6244301795959473,
      "learning_rate": 4.897058823529412e-05,
      "loss": 0.3287,
      "step": 530
    },
    {
      "epoch": 1.4516129032258065,
      "grad_norm": 1.189225196838379,
      "learning_rate": 4.860294117647059e-05,
      "loss": 0.312,
      "step": 540
    },
    {
      "epoch": 1.478494623655914,
      "grad_norm": 1.4115294218063354,
      "learning_rate": 4.823529411764706e-05,
      "loss": 0.2926,
      "step": 550
    },
    {
      "epoch": 1.5053763440860215,
      "grad_norm": 1.4817557334899902,
      "learning_rate": 4.7867647058823535e-05,
      "loss": 0.3235,
      "step": 560
    },
    {
      "epoch": 1.532258064516129,
      "grad_norm": 1.6872011423110962,
      "learning_rate": 4.75e-05,
      "loss": 0.3063,
      "step": 570
    },
    {
      "epoch": 1.5591397849462365,
      "grad_norm": 1.278544545173645,
      "learning_rate": 4.713235294117647e-05,
      "loss": 0.2841,
      "step": 580
    },
    {
      "epoch": 1.586021505376344,
      "grad_norm": 0.6752702593803406,
      "learning_rate": 4.6764705882352944e-05,
      "loss": 0.2612,
      "step": 590
    },
    {
      "epoch": 1.6129032258064515,
      "grad_norm": 2.4249863624572754,
      "learning_rate": 4.639705882352942e-05,
      "loss": 0.305,
      "step": 600
    },
    {
      "epoch": 1.639784946236559,
      "grad_norm": 1.2349271774291992,
      "learning_rate": 4.6029411764705885e-05,
      "loss": 0.3597,
      "step": 610
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 1.2003263235092163,
      "learning_rate": 4.566176470588235e-05,
      "loss": 0.3028,
      "step": 620
    },
    {
      "epoch": 1.6935483870967742,
      "grad_norm": 1.6255276203155518,
      "learning_rate": 4.5294117647058826e-05,
      "loss": 0.2779,
      "step": 630
    },
    {
      "epoch": 1.7204301075268817,
      "grad_norm": 1.1670256853103638,
      "learning_rate": 4.49264705882353e-05,
      "loss": 0.2669,
      "step": 640
    },
    {
      "epoch": 1.7473118279569892,
      "grad_norm": 2.464632511138916,
      "learning_rate": 4.455882352941177e-05,
      "loss": 0.2905,
      "step": 650
    },
    {
      "epoch": 1.7741935483870968,
      "grad_norm": 1.9065907001495361,
      "learning_rate": 4.4191176470588235e-05,
      "loss": 0.2726,
      "step": 660
    },
    {
      "epoch": 1.8010752688172043,
      "grad_norm": 0.8234511613845825,
      "learning_rate": 4.382352941176471e-05,
      "loss": 0.2915,
      "step": 670
    },
    {
      "epoch": 1.827956989247312,
      "grad_norm": 2.402251958847046,
      "learning_rate": 4.345588235294118e-05,
      "loss": 0.2732,
      "step": 680
    },
    {
      "epoch": 1.8548387096774195,
      "grad_norm": 1.2246395349502563,
      "learning_rate": 4.308823529411765e-05,
      "loss": 0.2802,
      "step": 690
    },
    {
      "epoch": 1.881720430107527,
      "grad_norm": 1.158555030822754,
      "learning_rate": 4.272058823529412e-05,
      "loss": 0.2617,
      "step": 700
    },
    {
      "epoch": 1.9086021505376345,
      "grad_norm": 1.1141995191574097,
      "learning_rate": 4.235294117647059e-05,
      "loss": 0.2673,
      "step": 710
    },
    {
      "epoch": 1.935483870967742,
      "grad_norm": 1.913309931755066,
      "learning_rate": 4.198529411764706e-05,
      "loss": 0.2405,
      "step": 720
    },
    {
      "epoch": 1.9623655913978495,
      "grad_norm": 2.977023124694824,
      "learning_rate": 4.161764705882353e-05,
      "loss": 0.2578,
      "step": 730
    },
    {
      "epoch": 1.989247311827957,
      "grad_norm": 1.2801146507263184,
      "learning_rate": 4.125e-05,
      "loss": 0.2856,
      "step": 740
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.27772074937820435,
      "eval_mean_iou": 0.7385167067174292,
      "eval_runtime": 2270.6089,
      "eval_samples_per_second": 0.22,
      "eval_steps_per_second": 0.028,
      "step": 744
    },
    {
      "epoch": 2.0161290322580645,
      "grad_norm": 2.3205504417419434,
      "learning_rate": 4.0882352941176474e-05,
      "loss": 0.2809,
      "step": 750
    },
    {
      "epoch": 2.043010752688172,
      "grad_norm": 1.0678551197052002,
      "learning_rate": 4.051470588235294e-05,
      "loss": 0.2346,
      "step": 760
    },
    {
      "epoch": 2.0698924731182795,
      "grad_norm": 1.9235864877700806,
      "learning_rate": 4.0147058823529415e-05,
      "loss": 0.2423,
      "step": 770
    },
    {
      "epoch": 2.096774193548387,
      "grad_norm": 0.9489643573760986,
      "learning_rate": 3.977941176470588e-05,
      "loss": 0.2635,
      "step": 780
    },
    {
      "epoch": 2.1236559139784945,
      "grad_norm": 1.4198095798492432,
      "learning_rate": 3.9411764705882356e-05,
      "loss": 0.2473,
      "step": 790
    },
    {
      "epoch": 2.150537634408602,
      "grad_norm": 0.7408244609832764,
      "learning_rate": 3.9044117647058823e-05,
      "loss": 0.2301,
      "step": 800
    },
    {
      "epoch": 2.1774193548387095,
      "grad_norm": 1.1773415803909302,
      "learning_rate": 3.86764705882353e-05,
      "loss": 0.2564,
      "step": 810
    },
    {
      "epoch": 2.204301075268817,
      "grad_norm": 2.4758238792419434,
      "learning_rate": 3.830882352941177e-05,
      "loss": 0.2466,
      "step": 820
    },
    {
      "epoch": 2.2311827956989245,
      "grad_norm": 1.044617772102356,
      "learning_rate": 3.794117647058824e-05,
      "loss": 0.2231,
      "step": 830
    },
    {
      "epoch": 2.258064516129032,
      "grad_norm": 1.3356150388717651,
      "learning_rate": 3.7573529411764706e-05,
      "loss": 0.2722,
      "step": 840
    },
    {
      "epoch": 2.28494623655914,
      "grad_norm": 2.0225510597229004,
      "learning_rate": 3.720588235294118e-05,
      "loss": 0.2632,
      "step": 850
    },
    {
      "epoch": 2.3118279569892475,
      "grad_norm": 0.9034848809242249,
      "learning_rate": 3.6838235294117654e-05,
      "loss": 0.2312,
      "step": 860
    },
    {
      "epoch": 2.338709677419355,
      "grad_norm": 0.8285485506057739,
      "learning_rate": 3.6470588235294114e-05,
      "loss": 0.2144,
      "step": 870
    },
    {
      "epoch": 2.3655913978494625,
      "grad_norm": 0.698492169380188,
      "learning_rate": 3.610294117647059e-05,
      "loss": 0.2467,
      "step": 880
    },
    {
      "epoch": 2.39247311827957,
      "grad_norm": 0.8052807450294495,
      "learning_rate": 3.573529411764706e-05,
      "loss": 0.2619,
      "step": 890
    },
    {
      "epoch": 2.4193548387096775,
      "grad_norm": 1.6775537729263306,
      "learning_rate": 3.5367647058823536e-05,
      "loss": 0.2326,
      "step": 900
    },
    {
      "epoch": 2.446236559139785,
      "grad_norm": 1.4213534593582153,
      "learning_rate": 3.5e-05,
      "loss": 0.2304,
      "step": 910
    },
    {
      "epoch": 2.4731182795698925,
      "grad_norm": 1.6079297065734863,
      "learning_rate": 3.463235294117647e-05,
      "loss": 0.2154,
      "step": 920
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.327897548675537,
      "learning_rate": 3.4264705882352945e-05,
      "loss": 0.2423,
      "step": 930
    },
    {
      "epoch": 2.5268817204301075,
      "grad_norm": 1.8939403295516968,
      "learning_rate": 3.389705882352941e-05,
      "loss": 0.2479,
      "step": 940
    },
    {
      "epoch": 2.553763440860215,
      "grad_norm": 0.8127350211143494,
      "learning_rate": 3.352941176470588e-05,
      "loss": 0.224,
      "step": 950
    },
    {
      "epoch": 2.5806451612903225,
      "grad_norm": 1.647425651550293,
      "learning_rate": 3.3161764705882353e-05,
      "loss": 0.2269,
      "step": 960
    },
    {
      "epoch": 2.60752688172043,
      "grad_norm": 1.1520613431930542,
      "learning_rate": 3.279411764705883e-05,
      "loss": 0.2324,
      "step": 970
    },
    {
      "epoch": 2.6344086021505375,
      "grad_norm": 1.117171049118042,
      "learning_rate": 3.2426470588235295e-05,
      "loss": 0.2301,
      "step": 980
    },
    {
      "epoch": 2.661290322580645,
      "grad_norm": 1.5180423259735107,
      "learning_rate": 3.205882352941177e-05,
      "loss": 0.2246,
      "step": 990
    },
    {
      "epoch": 2.688172043010753,
      "grad_norm": 0.9988721609115601,
      "learning_rate": 3.1691176470588236e-05,
      "loss": 0.2131,
      "step": 1000
    },
    {
      "epoch": 2.71505376344086,
      "grad_norm": 0.8764851689338684,
      "learning_rate": 3.132352941176471e-05,
      "loss": 0.2408,
      "step": 1010
    },
    {
      "epoch": 2.741935483870968,
      "grad_norm": 0.8121991753578186,
      "learning_rate": 3.095588235294118e-05,
      "loss": 0.2225,
      "step": 1020
    },
    {
      "epoch": 2.768817204301075,
      "grad_norm": 1.2960251569747925,
      "learning_rate": 3.058823529411765e-05,
      "loss": 0.2246,
      "step": 1030
    },
    {
      "epoch": 2.795698924731183,
      "grad_norm": 1.258334994316101,
      "learning_rate": 3.022058823529412e-05,
      "loss": 0.234,
      "step": 1040
    },
    {
      "epoch": 2.8225806451612905,
      "grad_norm": 1.5720072984695435,
      "learning_rate": 2.985294117647059e-05,
      "loss": 0.2386,
      "step": 1050
    },
    {
      "epoch": 2.849462365591398,
      "grad_norm": 0.810961127281189,
      "learning_rate": 2.948529411764706e-05,
      "loss": 0.2431,
      "step": 1060
    },
    {
      "epoch": 2.8763440860215055,
      "grad_norm": 0.7142563462257385,
      "learning_rate": 2.9117647058823534e-05,
      "loss": 0.2268,
      "step": 1070
    },
    {
      "epoch": 2.903225806451613,
      "grad_norm": 1.6188137531280518,
      "learning_rate": 2.8749999999999997e-05,
      "loss": 0.2336,
      "step": 1080
    },
    {
      "epoch": 2.9301075268817205,
      "grad_norm": 2.6040093898773193,
      "learning_rate": 2.838235294117647e-05,
      "loss": 0.2114,
      "step": 1090
    },
    {
      "epoch": 2.956989247311828,
      "grad_norm": 0.9177769422531128,
      "learning_rate": 2.8014705882352942e-05,
      "loss": 0.2353,
      "step": 1100
    },
    {
      "epoch": 2.9838709677419355,
      "grad_norm": 1.8818211555480957,
      "learning_rate": 2.7647058823529416e-05,
      "loss": 0.268,
      "step": 1110
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.25275036692619324,
      "eval_mean_iou": 0.7564176561752045,
      "eval_runtime": 2265.7759,
      "eval_samples_per_second": 0.221,
      "eval_steps_per_second": 0.028,
      "step": 1116
    },
    {
      "epoch": 3.010752688172043,
      "grad_norm": 4.323492050170898,
      "learning_rate": 2.727941176470588e-05,
      "loss": 0.2524,
      "step": 1120
    },
    {
      "epoch": 3.0376344086021505,
      "grad_norm": 0.8573275804519653,
      "learning_rate": 2.6911764705882354e-05,
      "loss": 0.2288,
      "step": 1130
    },
    {
      "epoch": 3.064516129032258,
      "grad_norm": 0.5874401330947876,
      "learning_rate": 2.6544117647058825e-05,
      "loss": 0.2201,
      "step": 1140
    },
    {
      "epoch": 3.0913978494623655,
      "grad_norm": 0.6279152631759644,
      "learning_rate": 2.6176470588235295e-05,
      "loss": 0.2156,
      "step": 1150
    },
    {
      "epoch": 3.118279569892473,
      "grad_norm": 0.6263675689697266,
      "learning_rate": 2.580882352941177e-05,
      "loss": 0.2123,
      "step": 1160
    },
    {
      "epoch": 3.1451612903225805,
      "grad_norm": 3.3552510738372803,
      "learning_rate": 2.5441176470588236e-05,
      "loss": 0.202,
      "step": 1170
    },
    {
      "epoch": 3.172043010752688,
      "grad_norm": 1.3422682285308838,
      "learning_rate": 2.5073529411764707e-05,
      "loss": 0.218,
      "step": 1180
    },
    {
      "epoch": 3.1989247311827955,
      "grad_norm": 1.2293705940246582,
      "learning_rate": 2.4705882352941178e-05,
      "loss": 0.2226,
      "step": 1190
    },
    {
      "epoch": 3.225806451612903,
      "grad_norm": 0.908237636089325,
      "learning_rate": 2.433823529411765e-05,
      "loss": 0.2084,
      "step": 1200
    },
    {
      "epoch": 3.252688172043011,
      "grad_norm": 1.5144034624099731,
      "learning_rate": 2.397058823529412e-05,
      "loss": 0.23,
      "step": 1210
    },
    {
      "epoch": 3.279569892473118,
      "grad_norm": 0.9092079401016235,
      "learning_rate": 2.360294117647059e-05,
      "loss": 0.2334,
      "step": 1220
    },
    {
      "epoch": 3.306451612903226,
      "grad_norm": 2.1208622455596924,
      "learning_rate": 2.323529411764706e-05,
      "loss": 0.2155,
      "step": 1230
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.5728407502174377,
      "learning_rate": 2.286764705882353e-05,
      "loss": 0.2118,
      "step": 1240
    },
    {
      "epoch": 3.360215053763441,
      "grad_norm": 1.3479692935943604,
      "learning_rate": 2.25e-05,
      "loss": 0.2176,
      "step": 1250
    },
    {
      "epoch": 3.3870967741935485,
      "grad_norm": 0.8874233365058899,
      "learning_rate": 2.2132352941176472e-05,
      "loss": 0.2426,
      "step": 1260
    },
    {
      "epoch": 3.413978494623656,
      "grad_norm": 0.9841548800468445,
      "learning_rate": 2.1764705882352943e-05,
      "loss": 0.2075,
      "step": 1270
    },
    {
      "epoch": 3.4408602150537635,
      "grad_norm": 0.8404819369316101,
      "learning_rate": 2.1397058823529413e-05,
      "loss": 0.2019,
      "step": 1280
    },
    {
      "epoch": 3.467741935483871,
      "grad_norm": 0.9388488531112671,
      "learning_rate": 2.1029411764705884e-05,
      "loss": 0.2322,
      "step": 1290
    },
    {
      "epoch": 3.4946236559139785,
      "grad_norm": 0.5303162932395935,
      "learning_rate": 2.066176470588235e-05,
      "loss": 0.2057,
      "step": 1300
    },
    {
      "epoch": 3.521505376344086,
      "grad_norm": 0.8426235318183899,
      "learning_rate": 2.0294117647058825e-05,
      "loss": 0.2175,
      "step": 1310
    },
    {
      "epoch": 3.5483870967741935,
      "grad_norm": 0.705420970916748,
      "learning_rate": 1.9926470588235296e-05,
      "loss": 0.1938,
      "step": 1320
    },
    {
      "epoch": 3.575268817204301,
      "grad_norm": 1.1084955930709839,
      "learning_rate": 1.9558823529411766e-05,
      "loss": 0.2137,
      "step": 1330
    },
    {
      "epoch": 3.6021505376344085,
      "grad_norm": 1.196427822113037,
      "learning_rate": 1.9191176470588237e-05,
      "loss": 0.2221,
      "step": 1340
    },
    {
      "epoch": 3.629032258064516,
      "grad_norm": 0.8579038977622986,
      "learning_rate": 1.8823529411764708e-05,
      "loss": 0.2193,
      "step": 1350
    },
    {
      "epoch": 3.6559139784946235,
      "grad_norm": 0.5083421468734741,
      "learning_rate": 1.8455882352941178e-05,
      "loss": 0.2202,
      "step": 1360
    },
    {
      "epoch": 3.682795698924731,
      "grad_norm": 1.0442408323287964,
      "learning_rate": 1.808823529411765e-05,
      "loss": 0.2136,
      "step": 1370
    },
    {
      "epoch": 3.709677419354839,
      "grad_norm": 0.689843475818634,
      "learning_rate": 1.772058823529412e-05,
      "loss": 0.2231,
      "step": 1380
    },
    {
      "epoch": 3.736559139784946,
      "grad_norm": 1.8678250312805176,
      "learning_rate": 1.735294117647059e-05,
      "loss": 0.2139,
      "step": 1390
    },
    {
      "epoch": 3.763440860215054,
      "grad_norm": 0.8962173461914062,
      "learning_rate": 1.698529411764706e-05,
      "loss": 0.1871,
      "step": 1400
    },
    {
      "epoch": 3.790322580645161,
      "grad_norm": 1.3406325578689575,
      "learning_rate": 1.6617647058823528e-05,
      "loss": 0.2135,
      "step": 1410
    },
    {
      "epoch": 3.817204301075269,
      "grad_norm": 0.8953884840011597,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 0.2001,
      "step": 1420
    },
    {
      "epoch": 3.8440860215053765,
      "grad_norm": 0.8144816160202026,
      "learning_rate": 1.588235294117647e-05,
      "loss": 0.1914,
      "step": 1430
    },
    {
      "epoch": 3.870967741935484,
      "grad_norm": 0.8312240839004517,
      "learning_rate": 1.5514705882352943e-05,
      "loss": 0.2253,
      "step": 1440
    },
    {
      "epoch": 3.8978494623655915,
      "grad_norm": 0.9162275195121765,
      "learning_rate": 1.5147058823529412e-05,
      "loss": 0.234,
      "step": 1450
    },
    {
      "epoch": 3.924731182795699,
      "grad_norm": 3.0641298294067383,
      "learning_rate": 1.4779411764705883e-05,
      "loss": 0.2281,
      "step": 1460
    },
    {
      "epoch": 3.9516129032258065,
      "grad_norm": 1.280775547027588,
      "learning_rate": 1.4411764705882352e-05,
      "loss": 0.2231,
      "step": 1470
    },
    {
      "epoch": 3.978494623655914,
      "grad_norm": 1.4689587354660034,
      "learning_rate": 1.4044117647058824e-05,
      "loss": 0.2134,
      "step": 1480
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.2462107390165329,
      "eval_mean_iou": 0.7628928661114556,
      "eval_runtime": 2268.182,
      "eval_samples_per_second": 0.22,
      "eval_steps_per_second": 0.028,
      "step": 1488
    },
    {
      "epoch": 4.005376344086022,
      "grad_norm": 0.8464104533195496,
      "learning_rate": 1.3676470588235296e-05,
      "loss": 0.2075,
      "step": 1490
    },
    {
      "epoch": 4.032258064516129,
      "grad_norm": 0.7802908420562744,
      "learning_rate": 1.3308823529411765e-05,
      "loss": 0.1989,
      "step": 1500
    },
    {
      "epoch": 4.059139784946237,
      "grad_norm": 1.1241410970687866,
      "learning_rate": 1.2941176470588238e-05,
      "loss": 0.1995,
      "step": 1510
    },
    {
      "epoch": 4.086021505376344,
      "grad_norm": 0.8177106976509094,
      "learning_rate": 1.2573529411764706e-05,
      "loss": 0.2087,
      "step": 1520
    },
    {
      "epoch": 4.112903225806452,
      "grad_norm": 3.1427581310272217,
      "learning_rate": 1.2205882352941177e-05,
      "loss": 0.2065,
      "step": 1530
    },
    {
      "epoch": 4.139784946236559,
      "grad_norm": 0.6341190934181213,
      "learning_rate": 1.1838235294117648e-05,
      "loss": 0.1745,
      "step": 1540
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 2.9803295135498047,
      "learning_rate": 1.1470588235294118e-05,
      "loss": 0.1955,
      "step": 1550
    },
    {
      "epoch": 4.193548387096774,
      "grad_norm": 0.9182974100112915,
      "learning_rate": 1.1102941176470589e-05,
      "loss": 0.2029,
      "step": 1560
    },
    {
      "epoch": 4.220430107526882,
      "grad_norm": 1.2674938440322876,
      "learning_rate": 1.0735294117647058e-05,
      "loss": 0.1993,
      "step": 1570
    },
    {
      "epoch": 4.247311827956989,
      "grad_norm": 4.092812538146973,
      "learning_rate": 1.036764705882353e-05,
      "loss": 0.1973,
      "step": 1580
    },
    {
      "epoch": 4.274193548387097,
      "grad_norm": 0.9056597948074341,
      "learning_rate": 1e-05,
      "loss": 0.197,
      "step": 1590
    },
    {
      "epoch": 4.301075268817204,
      "grad_norm": 1.0264934301376343,
      "learning_rate": 9.632352941176471e-06,
      "loss": 0.2177,
      "step": 1600
    },
    {
      "epoch": 4.327956989247312,
      "grad_norm": 0.7701675295829773,
      "learning_rate": 9.264705882352942e-06,
      "loss": 0.1853,
      "step": 1610
    },
    {
      "epoch": 4.354838709677419,
      "grad_norm": 0.655514121055603,
      "learning_rate": 8.897058823529413e-06,
      "loss": 0.222,
      "step": 1620
    },
    {
      "epoch": 4.381720430107527,
      "grad_norm": 1.064324975013733,
      "learning_rate": 8.529411764705883e-06,
      "loss": 0.1941,
      "step": 1630
    },
    {
      "epoch": 4.408602150537634,
      "grad_norm": 2.5494182109832764,
      "learning_rate": 8.161764705882354e-06,
      "loss": 0.2357,
      "step": 1640
    },
    {
      "epoch": 4.435483870967742,
      "grad_norm": 1.7266860008239746,
      "learning_rate": 7.794117647058825e-06,
      "loss": 0.1856,
      "step": 1650
    },
    {
      "epoch": 4.462365591397849,
      "grad_norm": 0.622667670249939,
      "learning_rate": 7.426470588235294e-06,
      "loss": 0.2051,
      "step": 1660
    },
    {
      "epoch": 4.489247311827957,
      "grad_norm": 1.2713983058929443,
      "learning_rate": 7.058823529411765e-06,
      "loss": 0.1915,
      "step": 1670
    },
    {
      "epoch": 4.516129032258064,
      "grad_norm": 0.9508959054946899,
      "learning_rate": 6.6911764705882356e-06,
      "loss": 0.2071,
      "step": 1680
    },
    {
      "epoch": 4.543010752688172,
      "grad_norm": 1.2395771741867065,
      "learning_rate": 6.323529411764706e-06,
      "loss": 0.2291,
      "step": 1690
    },
    {
      "epoch": 4.56989247311828,
      "grad_norm": 0.9174700975418091,
      "learning_rate": 5.955882352941177e-06,
      "loss": 0.1855,
      "step": 1700
    },
    {
      "epoch": 4.596774193548387,
      "grad_norm": 0.945000171661377,
      "learning_rate": 5.588235294117647e-06,
      "loss": 0.202,
      "step": 1710
    },
    {
      "epoch": 4.623655913978495,
      "grad_norm": 1.1977653503417969,
      "learning_rate": 5.220588235294118e-06,
      "loss": 0.2013,
      "step": 1720
    },
    {
      "epoch": 4.650537634408602,
      "grad_norm": 1.0206553936004639,
      "learning_rate": 4.852941176470589e-06,
      "loss": 0.2292,
      "step": 1730
    },
    {
      "epoch": 4.67741935483871,
      "grad_norm": 0.7292993664741516,
      "learning_rate": 4.485294117647059e-06,
      "loss": 0.212,
      "step": 1740
    },
    {
      "epoch": 4.704301075268817,
      "grad_norm": 1.5593689680099487,
      "learning_rate": 4.11764705882353e-06,
      "loss": 0.1875,
      "step": 1750
    },
    {
      "epoch": 4.731182795698925,
      "grad_norm": 2.9629056453704834,
      "learning_rate": 3.75e-06,
      "loss": 0.2067,
      "step": 1760
    },
    {
      "epoch": 4.758064516129032,
      "grad_norm": 2.335314989089966,
      "learning_rate": 3.3823529411764707e-06,
      "loss": 0.2296,
      "step": 1770
    },
    {
      "epoch": 4.78494623655914,
      "grad_norm": 8.964723587036133,
      "learning_rate": 3.0147058823529413e-06,
      "loss": 0.2185,
      "step": 1780
    },
    {
      "epoch": 4.811827956989247,
      "grad_norm": 0.7017725110054016,
      "learning_rate": 2.647058823529412e-06,
      "loss": 0.1987,
      "step": 1790
    },
    {
      "epoch": 4.838709677419355,
      "grad_norm": 0.5660343170166016,
      "learning_rate": 2.279411764705882e-06,
      "loss": 0.1889,
      "step": 1800
    },
    {
      "epoch": 4.865591397849462,
      "grad_norm": 1.252185344696045,
      "learning_rate": 1.911764705882353e-06,
      "loss": 0.219,
      "step": 1810
    },
    {
      "epoch": 4.89247311827957,
      "grad_norm": 1.0511506795883179,
      "learning_rate": 1.5441176470588236e-06,
      "loss": 0.2147,
      "step": 1820
    },
    {
      "epoch": 4.919354838709677,
      "grad_norm": 1.167315125465393,
      "learning_rate": 1.1764705882352942e-06,
      "loss": 0.2078,
      "step": 1830
    },
    {
      "epoch": 4.946236559139785,
      "grad_norm": 0.5970418453216553,
      "learning_rate": 8.088235294117648e-07,
      "loss": 0.1868,
      "step": 1840
    },
    {
      "epoch": 4.973118279569892,
      "grad_norm": 0.6073655486106873,
      "learning_rate": 4.411764705882353e-07,
      "loss": 0.2164,
      "step": 1850
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.610606849193573,
      "learning_rate": 7.352941176470589e-08,
      "loss": 0.1949,
      "step": 1860
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.24544771015644073,
      "eval_mean_iou": 0.7639695019760437,
      "eval_runtime": 2256.6247,
      "eval_samples_per_second": 0.222,
      "eval_steps_per_second": 0.028,
      "step": 1860
    }
  ],
  "logging_steps": 10,
  "max_steps": 1860,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0433462796288e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
